{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 18 21:28:45 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              55W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/bin/python\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!which python | grep DYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SinousEmbedding(nn.Module):\n",
    "    def __init__(self, dim) -> None:\n",
    "        super().__init__()\n",
    "        assert dim%2==0,NotImplementedError()\n",
    "        self.angles = (10000.**(-2/dim))**torch.arange(1,dim//2+1,1,dtype=torch.float).cuda()\n",
    "        self.angles.requires_grad_(False)\n",
    "    def forward(self,x):\n",
    "        angles = torch.einsum('m,i->im',self.angles,x.float())\n",
    "        return torch.cat((torch.sin(angles),torch.cos(angles)),dim=1)\n",
    "    \n",
    "class Attn(nn.Module):\n",
    "    def __init__(self,dim,head):\n",
    "        super().__init__()\n",
    "        assert dim%head==0,NotImplementedError()\n",
    "        self.head = head\n",
    "        self.head_dim = dim // head\n",
    "        self.Q = nn.Linear(dim,dim)\n",
    "        self.K = nn.Linear(dim,dim)\n",
    "        self.V = nn.Linear(dim,dim)\n",
    "        self.apply_init()\n",
    "\n",
    "    def apply_init(self):\n",
    "        self.Q.weight.data.normal_()\n",
    "        self.K.weight.data.normal_()\n",
    "        self.V.weight.data.normal_()\n",
    "        # self.V.weight.data.zero_()\n",
    "        # self.V.bias.data.zero_()\n",
    "        pass\n",
    "    \n",
    "    def forward(self,query,context):\n",
    "        # query: [B, H, head * head_dim]\n",
    "        # print('query',query)\n",
    "        # print('context',context)\n",
    "        q = self.Q(query).reshape(*query.shape[:2],self.head,self.head_dim) # [B, H, head, head_dim]\n",
    "        k = self.K(context).reshape(*context.shape[:2],self.head,self.head_dim) # [B, H, head, head_dim]\n",
    "        v = self.V(context).reshape(*context.shape[:2],self.head,self.head_dim) # [B, H_c, head, head_dim]\n",
    "        score = torch.einsum('bihd,bjhd->bijh',q,k) / self.head_dim**0.5 # [B, H_q, H_c, head]\n",
    "        # print('score',score * (self.head_dim ** 0.5))\n",
    "        score = F.softmax(score,dim=2) # [B, H_q, H_c, head]\n",
    "        # print('attention max:',score.max(),'attention min:',score.min(),'attention to time:',score[:,-1])\n",
    "        return torch.einsum('bijh,bjhd->bihd',score,v).reshape_as(query) # [B, H_q, head * head_dim]\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return 0.5 * x * (1 + torch.tanh(0.7978845608 * (x + 0.044715 * x**3)))\n",
    "    \n",
    "class SiLU(nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class Layer(nn.Module):\n",
    "\n",
    "    def __init__(self,dim,head):\n",
    "        super().__init__()\n",
    "        self.attn = Attn(dim,head)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim,dim),\n",
    "            GELU(),\n",
    "            nn.Linear(dim,dim)\n",
    "        )\n",
    "        self.condition_mlp = nn.Sequential(\n",
    "            nn.Linear(dim,2*dim),\n",
    "            SiLU(),\n",
    "            nn.Linear(2*dim,6*dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(dim,elementwise_affine=False)\n",
    "        self.norm2 = nn.LayerNorm(dim,elementwise_affine=False)\n",
    "        self.apply_init()\n",
    "\n",
    "    def apply_init(self):\n",
    "        self.condition_mlp[0].weight.data.zero_()\n",
    "        self.condition_mlp[0].bias.data.zero_()\n",
    "        self.condition_mlp[2].weight.data.zero_()\n",
    "        self.condition_mlp[2].bias.data.zero_()\n",
    "        self.mlp[0].weight.data.zero_()\n",
    "        self.mlp[0].bias.data.zero_()\n",
    "        self.mlp[2].weight.data.zero_()\n",
    "        self.mlp[2].bias.data.zero_()\n",
    "\n",
    "    def forward(self,x,condition):\n",
    "        alpha1,beta1,gamma1,alpha2,beta2,gamma2 = self.condition_mlp(condition).unsqueeze(1).chunk(6,dim=-1)\n",
    "\n",
    "        # first half\n",
    "        xc = x.clone()\n",
    "        x = self.norm1(x)\n",
    "        x = x * gamma1 + beta1\n",
    "        x = self.attn(x,x)\n",
    "        x = x * alpha1\n",
    "        x = x + xc\n",
    "\n",
    "        # second half\n",
    "        xc = x.clone()\n",
    "        x = self.norm2(x)\n",
    "        x = x * gamma2 + beta2\n",
    "        x = self.mlp(x)\n",
    "        x = x * alpha2\n",
    "        x = x + xc\n",
    "\n",
    "        return x\n",
    "\n",
    "class DiT(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 patch_size=4,\n",
    "                 hidden_dim=128,\n",
    "                 num_layers=3,\n",
    "                 image_size = 28*28,\n",
    "                 num_heads=4\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.num_patches = image_size // (patch_size * patch_size)\n",
    "        self.embedding = nn.Linear(patch_size * patch_size, hidden_dim)\n",
    "        self.pos_embedding = SinousEmbedding(hidden_dim)\n",
    "        self.t_embedding = nn.Sequential(\n",
    "            SinousEmbedding(hidden_dim),\n",
    "            nn.Linear(hidden_dim,hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim,hidden_dim)\n",
    "        )\n",
    "        self.patch_size = patch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList([Layer(hidden_dim,num_heads) for _ in range(num_layers)])\n",
    "        self.out_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.out_proj = nn.Linear(hidden_dim, patch_size * patch_size)\n",
    "        self.apply_init()\n",
    "\n",
    "    def apply_init(self):\n",
    "        self.out_proj.weight.data.zero_()\n",
    "        self.out_proj.bias.data.zero_()\n",
    "        # pass\n",
    "\n",
    "    def first(self,x,t):\n",
    "        t_embed = self.t_embedding(t)\n",
    "        # patchify the image x\n",
    "        x = x.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size) # [B, 1, H/4, W/4, 4, 4]\n",
    "        x_embed = self.embedding(x.reshape(x.shape[0],-1,self.patch_size*self.patch_size))\n",
    "        x_embed += self.pos_embedding(torch.arange(x_embed.shape[1],device=device))\n",
    "        data = torch.cat((x_embed,t_embed.unsqueeze(1)),dim=1)\n",
    "        # print('position embedding range:',pos_embed.min(),pos_embed.max(),pos_embed.std())\n",
    "        # print('x range:',data.min(),data.max(),data.std())\n",
    "        return data, t_embed\n",
    "    def forward(self,x,t):\n",
    "        x = x.reshape(x.shape[0],1,28,28)\n",
    "        inputs, conditioned = self.first(x,t)\n",
    "        for i,ly in enumerate(self.layers):\n",
    "            inputs = ly(inputs,conditioned)\n",
    "            # print('layer',i,'input.range:',inputs.min(),inputs.max())\n",
    "        # remove t token\n",
    "        inputs = inputs[:,:-1,:]\n",
    "        inputs = self.out_proj(self.out_norm(inputs))\n",
    "        # patchify the image x\n",
    "        length = 28 // self.patch_size\n",
    "        inputs = inputs.reshape(inputs.shape[0],length,length,self.patch_size,self.patch_size).permute(0,3,4,1,2).reshape(inputs.shape[0],self.patch_size*self.patch_size,length*length)\n",
    "        x = F.fold(inputs, (28,28), self.patch_size, stride=self.patch_size)\n",
    "        return x.reshape(x.shape[0],-1)\n",
    "\n",
    "# model = DiT().to(device)\n",
    "# x = torch.randn(7,1,28,28).to(device)\n",
    "# t = torch.randint(0,10,(7,)).to(device)\n",
    "# model(x,t).shape\n",
    "\n",
    "# img = torch.arange(12*12).reshape(1,1,12,12).float()\n",
    "# img\n",
    "# # separate to 7x7 4x4 patches\n",
    "# patch_size = 4\n",
    "# p = img.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "# good = p.squeeze(1).permute(0,3,4,1,2)\n",
    "# good.shape\n",
    "# # change patch back to 28x28\n",
    "\n",
    "# back = F.fold(good.reshape(img.shape[0],16,9), (12,12), 4, stride=4)\n",
    "# back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended /home/zhh24/DeepLearning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                     | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999, 0.9995, 0.9989, 0.9981, 0.9970, 0.9956, 0.9940, 0.9922, 0.9901,\n",
      "        0.9878, 0.9852, 0.9824, 0.9793, 0.9760, 0.9725, 0.9688, 0.9648, 0.9606,\n",
      "        0.9561, 0.9515, 0.9466, 0.9415, 0.9363, 0.9308, 0.9251, 0.9192, 0.9131,\n",
      "        0.9068, 0.9004, 0.8937, 0.8869, 0.8799, 0.8728, 0.8655, 0.8580, 0.8504,\n",
      "        0.8426, 0.8347, 0.8267, 0.8185, 0.8102, 0.8018, 0.7933, 0.7847, 0.7759,\n",
      "        0.7671, 0.7582, 0.7492, 0.7401, 0.7309, 0.7217, 0.7124, 0.7030, 0.6936,\n",
      "        0.6841, 0.6746, 0.6651, 0.6555, 0.6459, 0.6363, 0.6267, 0.6170, 0.6073,\n",
      "        0.5977, 0.5880, 0.5784, 0.5688, 0.5592, 0.5496, 0.5400, 0.5305, 0.5210,\n",
      "        0.5115, 0.5021, 0.4927, 0.4834, 0.4742, 0.4650, 0.4558, 0.4467, 0.4377,\n",
      "        0.4288, 0.4199, 0.4112, 0.4025, 0.3938, 0.3853, 0.3769, 0.3685, 0.3602,\n",
      "        0.3521, 0.3440, 0.3360, 0.3282, 0.3204, 0.3127, 0.3052, 0.2977, 0.2904,\n",
      "        0.2831, 0.2760, 0.2690, 0.2621, 0.2553, 0.2486, 0.2420, 0.2356, 0.2292,\n",
      "        0.2230, 0.2169, 0.2109, 0.2050, 0.1992, 0.1936, 0.1880, 0.1826, 0.1772,\n",
      "        0.1720, 0.1669, 0.1619, 0.1570, 0.1522, 0.1476, 0.1430, 0.1385, 0.1342,\n",
      "        0.1299, 0.1258, 0.1217, 0.1178, 0.1139, 0.1102, 0.1065, 0.1030, 0.0995,\n",
      "        0.0961, 0.0928, 0.0896, 0.0865, 0.0835, 0.0805, 0.0777, 0.0749, 0.0722,\n",
      "        0.0696, 0.0671, 0.0646, 0.0622, 0.0599, 0.0577, 0.0555, 0.0534, 0.0513,\n",
      "        0.0494, 0.0475, 0.0456, 0.0438, 0.0421, 0.0404, 0.0388, 0.0372, 0.0357,\n",
      "        0.0343, 0.0329, 0.0315, 0.0302, 0.0290, 0.0277, 0.0266, 0.0254, 0.0243,\n",
      "        0.0233, 0.0223, 0.0213, 0.0204, 0.0195, 0.0186, 0.0178, 0.0170, 0.0162,\n",
      "        0.0155, 0.0148, 0.0141, 0.0135, 0.0129, 0.0123, 0.0117, 0.0111, 0.0106,\n",
      "        0.0101, 0.0096, 0.0092, 0.0087, 0.0083, 0.0079, 0.0075, 0.0071, 0.0068,\n",
      "        0.0064, 0.0061], device='cuda:0')\n",
      "range of bars tensor(0.0061, device='cuda:0') tensor(0.9999, device='cuda:0')\n",
      "range of sigmas, tensor(0.0088, device='cuda:0') tensor(1., device='cuda:0')\n",
      "Number parameters of the model: 976400\n",
      "Model strcuture: DiT(\n",
      "  (embedding): Linear(in_features=16, out_features=128, bias=True)\n",
      "  (pos_embedding): SinousEmbedding()\n",
      "  (t_embedding): Sequential(\n",
      "    (0): SinousEmbedding()\n",
      "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): Layer(\n",
      "      (attn): Attn(\n",
      "        (Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (K): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (V): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (condition_mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=256, out_features=768, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "    )\n",
      "    (1): Layer(\n",
      "      (attn): Attn(\n",
      "        (Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (K): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (V): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (condition_mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=256, out_features=768, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "    )\n",
      "    (2): Layer(\n",
      "      (attn): Attn(\n",
      "        (Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (K): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (V): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (condition_mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=256, out_features=768, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
      "    )\n",
      "  )\n",
      "  (out_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (out_proj): Linear(in_features=128, out_features=16, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.3839: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 0, MSE 0.2044, [Valid] 0.2044: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DiT. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SinousEmbedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Attn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GELU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SiLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "epoch 1, loss 0.1772: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 1, MSE 0.1513, [Valid] 0.1513: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.65it/s]\n",
      "epoch 2, loss 0.1400: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 2, MSE 0.1293, [Valid] 0.1293: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.66it/s]\n",
      "epoch 3, loss 0.1244: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 3, MSE 0.1185, [Valid] 0.1185: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.66it/s]\n",
      "epoch 4, loss 0.1147: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 4, MSE 0.1128, [Valid] 0.1128: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.66it/s]\n",
      "epoch 5, loss 0.1106: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 5, MSE 0.1065, [Valid] 0.1065: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6, loss 0.1060: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 6, MSE 0.1041, [Valid] 0.1041: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.67it/s]\n",
      "epoch 7, loss 0.1034: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 7, MSE 0.1017, [Valid] 0.1017: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.66it/s]\n",
      "epoch 8, loss 0.1004: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 8, MSE 0.0985, [Valid] 0.0985: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.68it/s]\n",
      "epoch 9, loss 0.0981: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.99it/s]\n",
      "epoch 9, MSE 0.0972, [Valid] 0.0972: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.67it/s]\n",
      "epoch 10, loss 0.0964: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 10, MSE 0.0951, [Valid] 0.0951: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11, loss 0.0947: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 11, MSE 0.0942, [Valid] 0.0942: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.56it/s]\n",
      "epoch 12, loss 0.0937: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.97it/s]\n",
      "epoch 12, MSE 0.0899, [Valid] 0.0899: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.68it/s]\n",
      "epoch 13, loss 0.0922: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:32<00:00,  2.98it/s]\n",
      "epoch 13, MSE 0.0904, [Valid] 0.0904: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  8.67it/s]\n",
      "epoch 14, loss 0.0906:  36%|████████████████████████████████████▌                                                                | 34/94 [00:11<00:20,  2.89it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8080/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# parent_dir = os.path.abspath('/root/DeepLearning')\n",
    "parent_dir = os.path.abspath('/home/zhh24/DeepLearning')\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "print('appended',parent_dir)\n",
    "\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "mnist = utils.MNIST(batch_size=512)\n",
    "train_loader = mnist.train_dataloader\n",
    "valid_loader = mnist.valid_dataloader\n",
    "\n",
    "T=200\n",
    "beta1=1e-4 # variance of lowest temperature\n",
    "betaT=5e-2 # variance of highest temperature\n",
    "\n",
    "# step = torch.log(torch.tensor(betaT/beta1))/(T-1)\n",
    "# betas = beta1 * torch.exp(step*torch.arange(T,dtype=torch.float).to(device))\n",
    "step = (betaT-beta1)/(T-1)\n",
    "betas = torch.arange(T,dtype=torch.float,device=device) * step + beta1\n",
    "\n",
    "\n",
    "alphas = 1-betas\n",
    "alpha_bars = alphas.clone()\n",
    "for i in range(1,T):\n",
    "    alpha_bars[i] *= alpha_bars[i-1]\n",
    "\n",
    "print(alpha_bars)\n",
    "print('range of bars',alpha_bars.min(),alpha_bars.max())\n",
    "# print(alphas)\n",
    "# assert False\n",
    "\n",
    "sqrt = torch.sqrt\n",
    "sigmas = sqrt(betas * (1-alpha_bars / alphas)/(1-alpha_bars))\n",
    "sigmas[0] = 1\n",
    "print('range of sigmas,',sigmas.min(),sigmas.max())\n",
    "alphas = alphas.to(device)\n",
    "alpha_bars = alpha_bars.to(device)\n",
    "betas = betas.to(device)\n",
    "sigmas = sigmas.to(device)\n",
    "weights = torch.ones(T,dtype=torch.float,device=device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model:DiT,save_dir):\n",
    "    x = torch.randn([100,784]).to(device)\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*sigmas[t]\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "    grid = torchvision.utils.make_grid(post_process(x).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize(model,save_dir):\n",
    "    interval = (T-1) // 20\n",
    "    x = torch.randn([10,784]).to(device)\n",
    "    x_history = []\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*((betas[t])**0.5).to(device)\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "        x_history.append(x)\n",
    "    # print('cat.shape',torch.cat(x_history,dim=0).shape)\n",
    "    grid = torchvision.utils.make_grid(post_process(torch.stack(x_history,dim=0)[::interval,...]).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "    print('Saved visualize to',os.path.abspath(save_dir))\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_denoise(model,save_dir):\n",
    "    # get 10 images from the dataset\n",
    "    x,_ = next(iter(valid_loader))\n",
    "    x = x[:20,...].reshape(20,784).to(device)\n",
    "    x = pre_process(x)\n",
    "    t = torch.tensor([i * T // 20 for i in range(20)],dtype=torch.long,device=device)\n",
    "    noise = torch.randn_like(x).reshape(-1,784)\n",
    "    v1 = (sqrt(alpha_bars[t]).reshape(-1,1)*x).reshape(-1,784)\n",
    "    v2 = sqrt(1-alpha_bars[t]).reshape(-1,1)*noise\n",
    "    x_corr = v1+v2\n",
    "    est = model(x_corr,t)\n",
    "    x_rec = (x_corr - sqrt(1-alpha_bars[t]).reshape(-1,1)*est)/(sqrt(alpha_bars[t])).reshape(-1,1)\n",
    "    grid_orig = torchvision.utils.make_grid(post_process(x).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    grid_corr = torchvision.utils.make_grid(post_process(x_corr).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    grid_rec = torchvision.utils.make_grid(post_process(x_rec).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    # add noise level infomation to the image\n",
    "    noise_level = (1-alpha_bars[t]).reshape(-1).tolist()\n",
    "    ori_mse = noise.pow(2).mean(dim=1).reshape(-1).tolist()\n",
    "    mse = ((est-noise)**2).mean(dim=1).reshape(-1).tolist()\n",
    "    print(noise_level)\n",
    "    print(ori_mse)\n",
    "    print(mse)\n",
    "    grid = torch.cat([grid_orig,grid_corr,grid_rec],dim=1)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "    print('Saved denoise to',os.path.abspath(save_dir))\n",
    "\n",
    "def plot_loss(losses,save_dir):\n",
    "    losses_vals, t_vals = zip(*losses)\n",
    "    losses_vals = torch.cat(losses_vals,dim=0)\n",
    "    t_vals = torch.cat(t_vals,dim=0)\n",
    "    # print('t_vals',t_vals)\n",
    "    # print('losses_vals',losses_vals)\n",
    "\n",
    "    results = []\n",
    "    for t in range(T):\n",
    "        this_t = abs(t_vals.float()-float(t))<0.5\n",
    "        results.append(torch.sum(torch.where(this_t,losses_vals,torch.tensor(0.,device=device))).item() / (torch.sum(this_t.float())+1e-3).item())\n",
    "    plt.plot(results)\n",
    "    plt.ylim(0,max(results)* 1.2)\n",
    "    plt.savefig(save_dir)\n",
    "    plt.close()\n",
    "    # weights = (torch.tensor(results,device=device)) # weights\n",
    "    weights = torch.ones(T,dtype=torch.float,device=device)\n",
    "    # weights[:10]=0\n",
    "    # weights[10:80] /= 100\n",
    "    return weights\n",
    "\n",
    "def pre_process(x):\n",
    "    # do the logit transform\n",
    "    # return (torch.log(x+1e-3)-torch.log(1-x+1e-3))\n",
    "    return x*2-1 #MODIFIED\n",
    "    return (x+1)/2\n",
    "\n",
    "def post_process(x):\n",
    "    # return torch.sigmoid(x)\n",
    "    return (x+1)/2 #MODIFIED\n",
    "    return x*2-1\n",
    "\n",
    "def train(epochs,model:DiT,optimizer,eval_interval=5):\n",
    "    global weights\n",
    "    for epoch in range(epochs):\n",
    "        # print('weights normalized:',weights/weights.sum())\n",
    "        all_ts = torch.distributions.Categorical(weights).sample((50000,))\n",
    "        cnt = 0\n",
    "        model.train()\n",
    "        with tqdm(train_loader) as bar:\n",
    "            losses = []\n",
    "            for x,_ in bar:\n",
    "                cnt += x.shape[0]\n",
    "                x = pre_process(x.to(device))\n",
    "                epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                # ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                ts = all_ts[cnt-x.shape[0]:cnt]\n",
    "                alpha_tbars = alpha_bars[ts]\n",
    "                value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                out = model(value,ts) # [batch,784]\n",
    "\n",
    "                # loss = ((epss-out).pow(2).mean(dim=-1) * (betas[ts])/(2*alphas[ts]*(1-alpha_tbars))).sum(dim=0)\n",
    "                loss = ((epss-out).pow(2).mean(dim=-1)).mean(dim=0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "                bar.set_description('epoch {}, loss {:.4f}'.format(epoch,sum(losses)/len(losses)))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(valid_loader) as bar:\n",
    "                mses = []\n",
    "                losses = []\n",
    "                losses_for_t = []\n",
    "                for x,_ in bar:\n",
    "                    x = pre_process(x.to(device))\n",
    "                    epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                    ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                    # print(ts)\n",
    "                    alpha_tbars = alpha_bars[ts]\n",
    "                    value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                    out = model(value,ts)\n",
    "                    mse = F.mse_loss(epss,out)\n",
    "                    mses.append(mse.item())\n",
    "                    loss = ((epss-out).pow(2).mean(dim=-1))\n",
    "                    # loss = (epss-out).pow(2).mean(dim=-1)\n",
    "                    losses_for_t.append((loss.clone().detach(),ts))\n",
    "                    loss = (loss).mean(dim=0)\n",
    "                    losses.append(loss.item())\n",
    "                    bar.set_description('epoch {}, MSE {:.4f}, [Valid] {:.4f}'.format(epoch,sum(mses)/len(mses),sum(losses)/len(losses)))\n",
    "                    \n",
    "        if epoch % eval_interval == 0:\n",
    "            visualize(model,save_dir=os.path.join('./samples',f'diffuse_epoch_{epoch}.png'))\n",
    "            sample(model,save_dir=os.path.join('./samples',f'sample_epoch_{epoch}.png'))\n",
    "            # visualize_denoise(model,save_dir=os.path.join('./samples',f'denoise_epoch_{epoch}.png'))\n",
    "            weights = plot_loss(losses_for_t,save_dir=os.path.join('./samples',f'loss_epoch_{epoch}.png'))\n",
    "            torch.save(model,os.path.join('./samples',f'epoch_{epoch}.pt'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = DiT(\n",
    "        num_layers=3,\n",
    "        hidden_dim=128,\n",
    "        num_heads=8\n",
    "    ).to(device)\n",
    "    print('Number parameters of the model:', sum(p.numel() for p in model.parameters()))\n",
    "    print('Model strcuture:',model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    os.makedirs('./samples',exist_ok=True)\n",
    "    # sample(model,save_dir=os.path.join('./samples',f'init.png'))\n",
    "    # visualize(model,save_dir=os.path.join('./samples',f'init_visualize.png'))\n",
    "    train(200,model,optimizer,eval_interval=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
