{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 21:17:48 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              54W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/bin/python\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!which python | grep DYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SinousEmbedding(nn.Module):\n",
    "#     def __init__(self, dim) -> None:\n",
    "#         super().__init__()\n",
    "#         assert dim%2==0,NotImplementedError()\n",
    "#         self.angles = (1000.**(-2/dim))**torch.arange(1,dim//2+1,1,dtype=torch.float).cuda()\n",
    "#         self.angles.requires_grad_(False)\n",
    "#     def forward(self,x):\n",
    "#         angles = torch.einsum('m,i->im',self.angles,x.float())\n",
    "#         return torch.cat((torch.sin(angles),torch.cos(angles)),dim=1)\n",
    "\n",
    "# class DDPM(nn.Module):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.in_size = 28 * 28\n",
    "#         self.t_embedding_dim = 256\n",
    "#         self.t_embedding = SinousEmbedding(dim=self.t_embedding_dim)\n",
    "#         self.up = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(784+self.t_embedding_dim,64),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(64,32),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             # nn.Sequential(\n",
    "#             #     nn.Linear(256,256),\n",
    "#             #     # nn.LeakyReLU(0.1),\n",
    "#             # ),\n",
    "#         ])\n",
    "#         self.middle = nn.ModuleList([\n",
    "#             nn.Linear(32,32),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#         ])\n",
    "#         self.down= nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(32,32),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             # nn.Sequential(\n",
    "#             #     nn.Linear(256,256),\n",
    "#             #     # nn.LeakyReLU(0.1),\n",
    "#             # ),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(32,64),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#         ])\n",
    "#         self.end_mlp = nn.Linear(64,784)\n",
    "#         self.apply_init()\n",
    "\n",
    "#     def apply_init(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 nn.init.xavier_normal_(m.weight)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#     def forward(self,x,t):\n",
    "#         x = x.reshape(-1,784)\n",
    "#         ttensor = self.t_embedding(t) # [batch, 256]\n",
    "#         batch = x.shape[0]\n",
    "#         xc = x.clone()\n",
    "#         ups = []\n",
    "#         x = torch.cat((x,ttensor),dim=-1)\n",
    "#         for ly in self.up:\n",
    "#             x = ly(x)\n",
    "#             ups.append(x.clone())\n",
    "#         for ly in self.middle:\n",
    "#             x = ly(x)\n",
    "#         for ly in self.down:\n",
    "#             x = ly(x) + ups.pop()\n",
    "\n",
    "#         x = self.end_mlp(x)\n",
    "#         x = (x + xc)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SinousEmbedding(nn.Module):\n",
    "    def __init__(self, dim) -> None:\n",
    "        super().__init__()\n",
    "        assert dim%2==0,NotImplementedError()\n",
    "        self.angles = (500.**(-2/dim))**torch.arange(1,dim//2+1,1,dtype=torch.float).cuda()\n",
    "        self.angles.requires_grad_(False)\n",
    "    def forward(self,x):\n",
    "        angles = torch.einsum('m,i->im',self.angles,x.float())\n",
    "        return torch.cat((torch.sin(angles),torch.cos(angles)),dim=1)\n",
    "\n",
    "class F_x_t(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,out_size,kernel_size=3,t_shape=64) -> None:\n",
    "        super().__init__()\n",
    "        # self.t_channels = out_channels // 2\n",
    "        # self.conv_channels = out_channels - self.t_channels\n",
    "        self.t_channels = out_channels\n",
    "        self.conv_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, self.conv_channels, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.out_size = out_size\n",
    "        self.fc = nn.Linear(t_shape, self.t_channels)\n",
    "        # self.fc = nn.Embedding(t_shape, self.t_num)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if self.t_channels == 0:\n",
    "            return self.conv(x)\n",
    "        # return torch.cat([self.conv(x),self.fc(t).unsqueeze(-1).unsqueeze(-1).expand(t.shape[0], self.t_channels, self.out_size, self.out_size)],dim=1).relu()\n",
    "        return (self.conv(x) + self.fc(t).unsqueeze(-1).unsqueeze(-1).expand(t.shape[0], self.t_channels, self.out_size, self.out_size)).relu()\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.t_embedding_dim = 32\n",
    "        self.t_embedding = SinousEmbedding(dim=self.t_embedding_dim)\n",
    "        self.up= nn.ModuleList([\n",
    "            F_x_t(in_channels=1,out_channels=32,out_size=32,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=32,out_channels=128,out_size=16,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=128,out_channels=128,out_size=8,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "        ])\n",
    "        self.middle = nn.ModuleList([\n",
    "            nn.Identity()\n",
    "        ])\n",
    "        self.down= nn.ModuleList([\n",
    "            F_x_t(in_channels=128,out_channels=128,out_size=4,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=128,out_channels=128,out_size=8,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=128,out_channels=32,out_size=16,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "        ])\n",
    "        self.end_mlp = nn.Conv2d(32,1,kernel_size=3,padding=1)\n",
    "        self.apply_init()\n",
    "    \n",
    "    def apply_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self,x,t):\n",
    "        x = x.reshape(-1,1,28,28)\n",
    "        x = F.pad(x,(2,2,2,2),mode='constant',value=0)\n",
    "        ttensor = self.t_embedding(t) # [batch, 256]\n",
    "        batch = x.shape[0]\n",
    "        # xc = x.clone()\n",
    "        ups = []\n",
    "        for ly in self.up:\n",
    "            x = ly(x,ttensor)\n",
    "            ups.append(x.clone()) # append: 28x28, 14x14\n",
    "            x = nn.AvgPool2d(2)(x)\n",
    "        for ly in self.middle:\n",
    "            x = ly(x)\n",
    "        for ly in self.down:\n",
    "            x = ly(x,ttensor)\n",
    "            x = nn.Upsample(scale_factor=2)(x) + ups.pop()\n",
    "        x = self.end_mlp(x)\n",
    "        x = x[:,:,2:30,2:30]\n",
    "        return x.reshape(batch,28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended /home/zhh24/DeepLearning\n",
      "tensor([0.9999, 0.9997, 0.9994, 0.9990, 0.9985, 0.9979, 0.9972, 0.9964, 0.9955,\n",
      "        0.9945, 0.9934, 0.9922, 0.9909, 0.9895, 0.9881, 0.9865, 0.9848, 0.9830,\n",
      "        0.9812, 0.9792, 0.9771, 0.9750, 0.9728, 0.9704, 0.9680, 0.9655, 0.9629,\n",
      "        0.9602, 0.9574, 0.9545, 0.9516, 0.9485, 0.9454, 0.9422, 0.9389, 0.9355,\n",
      "        0.9320, 0.9285, 0.9249, 0.9212, 0.9174, 0.9135, 0.9096, 0.9056, 0.9015,\n",
      "        0.8974, 0.8932, 0.8889, 0.8845, 0.8801, 0.8756, 0.8711, 0.8664, 0.8618,\n",
      "        0.8570, 0.8522, 0.8474, 0.8425, 0.8375, 0.8325, 0.8274, 0.8223, 0.8171,\n",
      "        0.8118, 0.8066, 0.8012, 0.7959, 0.7905, 0.7850, 0.7795, 0.7740, 0.7684,\n",
      "        0.7628, 0.7572, 0.7515, 0.7458, 0.7400, 0.7342, 0.7284, 0.7226, 0.7168,\n",
      "        0.7109, 0.7050, 0.6991, 0.6931, 0.6872, 0.6812, 0.6752, 0.6692, 0.6632,\n",
      "        0.6571, 0.6511, 0.6450, 0.6390, 0.6329, 0.6268, 0.6207, 0.6147, 0.6086,\n",
      "        0.6025, 0.5964, 0.5903, 0.5842, 0.5782, 0.5721, 0.5660, 0.5600, 0.5539,\n",
      "        0.5479, 0.5419, 0.5358, 0.5298, 0.5238, 0.5179, 0.5119, 0.5060, 0.5001,\n",
      "        0.4942, 0.4883, 0.4824, 0.4766, 0.4708, 0.4650, 0.4592, 0.4535, 0.4478,\n",
      "        0.4421, 0.4364, 0.4308, 0.4252, 0.4196, 0.4141, 0.4086, 0.4031, 0.3977,\n",
      "        0.3922, 0.3869, 0.3815, 0.3762, 0.3710, 0.3657, 0.3605, 0.3554, 0.3503,\n",
      "        0.3452, 0.3401, 0.3351, 0.3302, 0.3253, 0.3204, 0.3155, 0.3108, 0.3060,\n",
      "        0.3013, 0.2966, 0.2920, 0.2874, 0.2829, 0.2784, 0.2739, 0.2695, 0.2651,\n",
      "        0.2608, 0.2565, 0.2523, 0.2481, 0.2440, 0.2399, 0.2358, 0.2318, 0.2278,\n",
      "        0.2239, 0.2201, 0.2162, 0.2124, 0.2087, 0.2050, 0.2014, 0.1978, 0.1942,\n",
      "        0.1907, 0.1872, 0.1838, 0.1804, 0.1771, 0.1738, 0.1705, 0.1673, 0.1642,\n",
      "        0.1610, 0.1580, 0.1549, 0.1519, 0.1490, 0.1461, 0.1432, 0.1404, 0.1376,\n",
      "        0.1349, 0.1322], device='cuda:0')\n",
      "tensor([0.9999, 0.9998, 0.9997, 0.9996, 0.9995, 0.9994, 0.9993, 0.9992, 0.9991,\n",
      "        0.9990, 0.9989, 0.9988, 0.9987, 0.9986, 0.9985, 0.9984, 0.9983, 0.9982,\n",
      "        0.9981, 0.9980, 0.9979, 0.9978, 0.9977, 0.9976, 0.9975, 0.9974, 0.9973,\n",
      "        0.9972, 0.9971, 0.9970, 0.9969, 0.9968, 0.9967, 0.9966, 0.9965, 0.9964,\n",
      "        0.9963, 0.9962, 0.9961, 0.9960, 0.9959, 0.9958, 0.9957, 0.9956, 0.9955,\n",
      "        0.9954, 0.9953, 0.9952, 0.9951, 0.9950, 0.9949, 0.9948, 0.9947, 0.9946,\n",
      "        0.9945, 0.9944, 0.9943, 0.9942, 0.9941, 0.9940, 0.9939, 0.9938, 0.9937,\n",
      "        0.9936, 0.9935, 0.9934, 0.9933, 0.9932, 0.9931, 0.9930, 0.9929, 0.9928,\n",
      "        0.9927, 0.9926, 0.9925, 0.9924, 0.9923, 0.9922, 0.9921, 0.9920, 0.9919,\n",
      "        0.9918, 0.9917, 0.9916, 0.9915, 0.9914, 0.9913, 0.9912, 0.9911, 0.9910,\n",
      "        0.9909, 0.9908, 0.9907, 0.9906, 0.9905, 0.9904, 0.9903, 0.9902, 0.9901,\n",
      "        0.9900, 0.9899, 0.9898, 0.9897, 0.9896, 0.9895, 0.9894, 0.9893, 0.9892,\n",
      "        0.9891, 0.9890, 0.9889, 0.9888, 0.9887, 0.9886, 0.9885, 0.9884, 0.9883,\n",
      "        0.9882, 0.9881, 0.9880, 0.9879, 0.9878, 0.9877, 0.9876, 0.9875, 0.9874,\n",
      "        0.9873, 0.9872, 0.9871, 0.9870, 0.9869, 0.9868, 0.9867, 0.9866, 0.9865,\n",
      "        0.9864, 0.9863, 0.9862, 0.9861, 0.9860, 0.9859, 0.9858, 0.9857, 0.9856,\n",
      "        0.9855, 0.9854, 0.9853, 0.9852, 0.9851, 0.9850, 0.9849, 0.9848, 0.9847,\n",
      "        0.9846, 0.9845, 0.9844, 0.9843, 0.9842, 0.9841, 0.9840, 0.9839, 0.9838,\n",
      "        0.9837, 0.9836, 0.9835, 0.9834, 0.9833, 0.9832, 0.9831, 0.9830, 0.9829,\n",
      "        0.9828, 0.9827, 0.9826, 0.9825, 0.9824, 0.9823, 0.9822, 0.9821, 0.9820,\n",
      "        0.9819, 0.9818, 0.9817, 0.9816, 0.9815, 0.9814, 0.9813, 0.9812, 0.9811,\n",
      "        0.9810, 0.9809, 0.9808, 0.9807, 0.9806, 0.9805, 0.9804, 0.9803, 0.9802,\n",
      "        0.9801, 0.9800], device='cuda:0')\n",
      "Number parameters of the model: 536257\n",
      "Model strcuture: DDPM(\n",
      "  (t_embedding): SinousEmbedding()\n",
      "  (up): ModuleList(\n",
      "    (0): F_x_t(\n",
      "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (1): F_x_t(\n",
      "      (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): F_x_t(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (middle): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      "  (down): ModuleList(\n",
      "    (0): F_x_t(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "    (1): F_x_t(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "    (2): F_x_t(\n",
      "      (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (end_mlp): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 3.4624:   1%|█                                                                                                      | 1/94 [00:00<00:17,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/init_visualize.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 66.8709: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.04it/s]\n",
      "epoch 0, MSE 1.0364, [Valid] 1.0364: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DDPM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SinousEmbedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type F_x_t. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "epoch 1, loss 0.8510: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.05it/s]\n",
      "epoch 1, MSE 0.6887, [Valid] 0.6887: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.48it/s]\n",
      "epoch 2, loss 0.5796: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.77it/s]\n",
      "epoch 2, MSE 0.4919, [Valid] 0.4919: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.30it/s]\n",
      "epoch 3, loss 0.4398: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.77it/s]\n",
      "epoch 3, MSE 0.3961, [Valid] 0.3961: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.40it/s]\n",
      "epoch 4, loss 0.3692: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.80it/s]\n",
      "epoch 4, MSE 0.3453, [Valid] 0.3453: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.39it/s]\n",
      "epoch 5, loss 0.3267: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.80it/s]\n",
      "epoch 5, MSE 0.3120, [Valid] 0.3120: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6, loss 0.3000: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.86it/s]\n",
      "epoch 6, MSE 0.2873, [Valid] 0.2873: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.39it/s]\n",
      "epoch 7, loss 0.2770: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.80it/s]\n",
      "epoch 7, MSE 0.2695, [Valid] 0.2695: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.32it/s]\n",
      "epoch 8, loss 0.2619: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.87it/s]\n",
      "epoch 8, MSE 0.2546, [Valid] 0.2546: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.42it/s]\n",
      "epoch 9, loss 0.2471: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.82it/s]\n",
      "epoch 9, MSE 0.2435, [Valid] 0.2435: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 10, loss 0.2363: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.81it/s]\n",
      "epoch 10, MSE 0.2318, [Valid] 0.2318: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11, loss 0.2249: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.02it/s]\n",
      "epoch 11, MSE 0.2259, [Valid] 0.2259: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.45it/s]\n",
      "epoch 12, loss 0.2180: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.04it/s]\n",
      "epoch 12, MSE 0.2156, [Valid] 0.2156: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.42it/s]\n",
      "epoch 13, loss 0.2100: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.77it/s]\n",
      "epoch 13, MSE 0.2056, [Valid] 0.2056: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 14, loss 0.2037: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.78it/s]\n",
      "epoch 14, MSE 0.2009, [Valid] 0.2009: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.38it/s]\n",
      "epoch 15, loss 0.1981: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.76it/s]\n",
      "epoch 15, MSE 0.1961, [Valid] 0.1961: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16, loss 0.1914: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.84it/s]\n",
      "epoch 16, MSE 0.1902, [Valid] 0.1902: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.31it/s]\n",
      "epoch 17, loss 0.1869: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.83it/s]\n",
      "epoch 17, MSE 0.1840, [Valid] 0.1840: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.38it/s]\n",
      "epoch 18, loss 0.1831: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.90it/s]\n",
      "epoch 18, MSE 0.1799, [Valid] 0.1799: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 19, loss 0.1786: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.81it/s]\n",
      "epoch 19, MSE 0.1784, [Valid] 0.1784: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.42it/s]\n",
      "epoch 20, loss 0.1743: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.76it/s]\n",
      "epoch 20, MSE 0.1759, [Valid] 0.1759: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21, loss 0.1694: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.07it/s]\n",
      "epoch 21, MSE 0.1686, [Valid] 0.1686: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.44it/s]\n",
      "epoch 22, loss 0.1659: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.02it/s]\n",
      "epoch 22, MSE 0.1631, [Valid] 0.1631: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.48it/s]\n",
      "epoch 23, loss 0.1631: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.86it/s]\n",
      "epoch 23, MSE 0.1610, [Valid] 0.1610: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.35it/s]\n",
      "epoch 24, loss 0.1597: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.91it/s]\n",
      "epoch 24, MSE 0.1576, [Valid] 0.1576: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.44it/s]\n",
      "epoch 25, loss 0.1563: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.96it/s]\n",
      "epoch 25, MSE 0.1559, [Valid] 0.1559: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 26, loss 0.1518: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.84it/s]\n",
      "epoch 26, MSE 0.1528, [Valid] 0.1528: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 27, loss 0.1521: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.76it/s]\n",
      "epoch 27, MSE 0.1504, [Valid] 0.1504: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.37it/s]\n",
      "epoch 28, loss 0.1465: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.80it/s]\n",
      "epoch 28, MSE 0.1447, [Valid] 0.1447: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 29, loss 0.1437: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.84it/s]\n",
      "epoch 29, MSE 0.1461, [Valid] 0.1461: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.41it/s]\n",
      "epoch 30, loss 0.1434: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.81it/s]\n",
      "epoch 30, MSE 0.1403, [Valid] 0.1403: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 31, loss 0.1397: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.05it/s]\n",
      "epoch 31, MSE 0.1396, [Valid] 0.1396: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.48it/s]\n",
      "epoch 32, loss 0.1391: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.11it/s]\n",
      "epoch 32, MSE 0.1393, [Valid] 0.1393: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.43it/s]\n",
      "epoch 33, loss 0.1361: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.76it/s]\n",
      "epoch 33, MSE 0.1351, [Valid] 0.1351: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.40it/s]\n",
      "epoch 34, loss 0.1343: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.89it/s]\n",
      "epoch 34, MSE 0.1320, [Valid] 0.1320: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.44it/s]\n",
      "epoch 35, loss 0.1315: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.62it/s]\n",
      "epoch 35, MSE 0.1318, [Valid] 0.1318: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 36, loss 0.1302:  26%|█████████████████████████▊                                                                           | 24/94 [00:03<00:09,  7.43it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8080/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath('/home/zhh24/DeepLearning')\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "print('appended',parent_dir)\n",
    "\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mnist = utils.MNIST(batch_size=512)\n",
    "train_loader = mnist.train_dataloader\n",
    "valid_loader = mnist.valid_dataloader\n",
    "T=200\n",
    "beta1=1e-4 # variance of lowest temperature\n",
    "betaT=2e-2 # variance of highest temperature\n",
    "# step = torch.log(torch.tensor(betaT/beta1))/(T-1)\n",
    "# betas = beta1 * torch.exp(step*torch.arange(T,dtype=torch.float).to(device))\n",
    "step = (betaT-beta1)/(T-1)\n",
    "betas = torch.arange(beta1,betaT+step,step).to(device)\n",
    "\n",
    "alphas = 1-betas\n",
    "alpha_bars = alphas.clone()\n",
    "for i in range(1,T):\n",
    "    alpha_bars[i] *= alpha_bars[i-1]\n",
    "print(alpha_bars)\n",
    "print(alphas)\n",
    "sqrt = torch.sqrt\n",
    "sigmas = sqrt(betas)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model:DDPM,save_dir):\n",
    "    x = torch.randn([100,784]).to(device)\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*sigmas[t]\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "    grid = torchvision.utils.make_grid(post_process(x).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize(model,save_dir):\n",
    "    x = torch.randn([10,784]).to(device)\n",
    "    x_history = []\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*((betas[t])**0.5).to(device)\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "        x_history.append(x)\n",
    "    # print('cat.shape',torch.cat(x_history,dim=0).shape)\n",
    "    grid = torchvision.utils.make_grid(post_process(torch.cat(x_history,dim=0)[3::4,...]).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "    print('Saved visualize to',os.path.abspath(save_dir))\n",
    "\n",
    "def pre_process(x):\n",
    "    # do the logit transform\n",
    "    # return (torch.log(x+1e-3)-torch.log(1-x+1e-3))\n",
    "    return (x+1)/2\n",
    "\n",
    "def post_process(x):\n",
    "    # return torch.sigmoid(x)\n",
    "    return x*2-1\n",
    "\n",
    "def train(epochs,model:DDPM,optimizer,eval_interval=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        with tqdm(train_loader) as bar:\n",
    "            losses = []\n",
    "            for x,_ in bar:\n",
    "                x = pre_process(x.to(device))\n",
    "                epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                alpha_tbars = alpha_bars[ts]\n",
    "                value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                out = model(value,ts) # [batch,784]\n",
    "                # loss = ((epss-out).pow(2).mean(dim=-1) * (betas[ts])/(2*alphas[ts]*(1-alpha_tbars))).sum(dim=0)\n",
    "                loss = (epss-out).pow(2).mean(dim=-1).mean(dim=0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "                bar.set_description('epoch {}, loss {:.4f}'.format(epoch,sum(losses)/len(losses)))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(valid_loader) as bar:\n",
    "                mses = []\n",
    "                losses = []\n",
    "                for x,_ in bar:\n",
    "                    x = pre_process(x.to(device))\n",
    "                    epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                    ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                    alpha_tbars = alpha_bars[ts]\n",
    "                    value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                    out = model(value,ts)\n",
    "                    mse = F.mse_loss(epss,out)\n",
    "                    mses.append(mse.item())\n",
    "                    # loss = ((epss-out).pow(2).mean(dim=-1) * (betas[ts])/(2*alphas[ts]*(1-alpha_tbars))).sum(dim=0)\n",
    "                    loss = (epss-out).pow(2).mean(dim=-1).mean(dim=0)\n",
    "                    losses.append(loss.item())\n",
    "                    bar.set_description('epoch {}, MSE {:.4f}, [Valid] {:.4f}'.format(epoch,sum(mses)/len(mses),sum(losses)/len(losses)))\n",
    "                    \n",
    "        if epoch % eval_interval == 0:\n",
    "            visualize(model,save_dir=os.path.join('./samples',f'diffuse_epoch_{epoch}.png'))\n",
    "            sample(model,save_dir=os.path.join('./samples',f'sample_epoch_{epoch}.png'))\n",
    "            torch.save(model,os.path.join('./samples',f'epoch_{epoch}.pt'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = DDPM().to(device)\n",
    "    print('Number parameters of the model:', sum(p.numel() for p in model.parameters()))\n",
    "    print('Model strcuture:',model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
    "    os.makedirs('./samples',exist_ok=True)\n",
    "    sample(model,save_dir=os.path.join('./samples',f'init.png'))\n",
    "    visualize(model,save_dir=os.path.join('./samples',f'init_visualize.png'))\n",
    "    train(200,model,optimizer,eval_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
