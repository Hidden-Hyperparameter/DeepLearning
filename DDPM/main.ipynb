{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 16 18:56:27 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              41W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/bin/python\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!which python | grep DYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(3407)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SinousEmbedding(nn.Module):\n",
    "#     def __init__(self, dim) -> None:\n",
    "#         super().__init__()\n",
    "#         assert dim%2==0,NotImplementedError()\n",
    "#         self.angles = (1000.**(-2/dim))**torch.arange(1,dim//2+1,1,dtype=torch.float).cuda()\n",
    "#         self.angles.requires_grad_(False)\n",
    "#     def forward(self,x):\n",
    "#         angles = torch.einsum('m,i->im',self.angles,x.float())\n",
    "#         return torch.cat((torch.sin(angles),torch.cos(angles)),dim=1)\n",
    "\n",
    "# class DDPM(nn.Module):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.in_size = 28 * 28\n",
    "#         self.t_embedding_dim = 256\n",
    "#         self.t_embedding = SinousEmbedding(dim=self.t_embedding_dim)\n",
    "#         self.up = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(784+self.t_embedding_dim,64),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(64,32),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             # nn.Sequential(\n",
    "#             #     nn.Linear(256,256),\n",
    "#             #     # nn.LeakyReLU(0.1),\n",
    "#             # ),\n",
    "#         ])\n",
    "#         self.middle = nn.ModuleList([\n",
    "#             nn.Linear(32,32),\n",
    "#             # nn.LeakyReLU(0.1),\n",
    "#         ])\n",
    "#         self.down= nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(32,32),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#             # nn.Sequential(\n",
    "#             #     nn.Linear(256,256),\n",
    "#             #     # nn.LeakyReLU(0.1),\n",
    "#             # ),\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(32,64),\n",
    "#                 nn.ReLU(),\n",
    "#             ),\n",
    "#         ])\n",
    "#         self.end_mlp = nn.Linear(64,784)\n",
    "#         self.apply_init()\n",
    "\n",
    "#     def apply_init(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 nn.init.xavier_normal_(m.weight)\n",
    "#                 nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#     def forward(self,x,t):\n",
    "#         x = x.reshape(-1,784)\n",
    "#         ttensor = self.t_embedding(t) # [batch, 256]\n",
    "#         batch = x.shape[0]\n",
    "#         xc = x.clone()\n",
    "#         ups = []\n",
    "#         x = torch.cat((x,ttensor),dim=-1)\n",
    "#         for ly in self.up:\n",
    "#             x = ly(x)\n",
    "#             ups.append(x.clone())\n",
    "#         for ly in self.middle:\n",
    "#             x = ly(x)\n",
    "#         for ly in self.down:\n",
    "#             x = ly(x) + ups.pop()\n",
    "\n",
    "#         x = self.end_mlp(x)\n",
    "#         x = (x + xc)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SinousEmbedding(nn.Module):\n",
    "    def __init__(self, dim) -> None:\n",
    "        super().__init__()\n",
    "        assert dim%2==0,NotImplementedError()\n",
    "        self.angles = (1000.**(-2/dim))**torch.arange(1,dim//2+1,1,dtype=torch.float).cuda()\n",
    "        self.angles.requires_grad_(False)\n",
    "    def forward(self,x):\n",
    "        angles = torch.einsum('m,i->im',self.angles,x.float())\n",
    "        return torch.cat((torch.sin(angles),torch.cos(angles)),dim=1)\n",
    "\n",
    "class F_x_t(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,out_size,kernel_size=3,t_shape=64,attn=False,attn_dim=32) -> None:\n",
    "        super().__init__()\n",
    "        # self.t_channels = out_channels // 2\n",
    "        # self.conv_channels = out_channels - self.t_channels\n",
    "        self.t_channels = out_channels\n",
    "        self.conv_channels = out_channels\n",
    "        self.conv = nn.Conv2d(in_channels, self.conv_channels, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.out_size = out_size\n",
    "        self.fc = nn.Linear(t_shape, self.t_channels)\n",
    "        self.attn = attn\n",
    "        if attn:\n",
    "            self.Q  = nn.Conv2d(out_channels, attn_dim, kernel_size=1)\n",
    "            self.K  = nn.Conv2d(out_channels, attn_dim, kernel_size=1)\n",
    "            self.V  = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        # self.fc = nn.Embedding(t_shape, self.t_num)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if self.t_channels == 0:\n",
    "            raise NotImplementedError()\n",
    "            return self.conv(x)\n",
    "        # return torch.cat([self.conv(x),self.fc(t).unsqueeze(-1).unsqueeze(-1).expand(t.shape[0], self.t_channels, self.out_size, self.out_size)],dim=1).relu()\n",
    "        val = (self.conv(x) + self.fc(t).unsqueeze(-1).unsqueeze(-1).expand(t.shape[0], self.t_channels, self.out_size, self.out_size))\n",
    "        if self.attn:\n",
    "            q = self.Q(val)\n",
    "            k = self.K(val)\n",
    "            v = self.V(val)\n",
    "            attn_score = torch.einsum('bchw,bcxy->bhwxy',q,k).reshape(q.shape[0],*q.shape[-2:],-1)\n",
    "            attn_score = attn_score.softmax(dim=-1).reshape(q.shape[0],*q.shape[-2:],*k.shape[-2:])\n",
    "            return torch.einsum('bhwxy,bcxy->bchw',attn_score,v).relu()\n",
    "        return val.relu()\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.t_embedding_dim = 32\n",
    "        self.t_embedding = SinousEmbedding(dim=self.t_embedding_dim)\n",
    "        self.up= nn.ModuleList([\n",
    "            F_x_t(in_channels=1,out_channels=32,out_size=32,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=32,out_channels=64,out_size=16,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=64,out_channels=128,out_size=8,kernel_size=3,t_shape=self.t_embedding_dim,attn=False),\n",
    "            # F_x_t(in_channels=128,out_channels=128,out_size=4,kernel_size=1,t_shape=self.t_embedding_dim),\n",
    "        ])\n",
    "        self.middle = nn.ModuleList([\n",
    "            # nn.Identity()\n",
    "            F_x_t(in_channels=128,out_channels=128,out_size=4,kernel_size=1,t_shape=self.t_embedding_dim,attn=False),\n",
    "        ])\n",
    "        self.down= nn.ModuleList([\n",
    "            # F_x_t(in_channels=128,out_channels=128,out_size=2,kernel_size=1,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=128,out_channels=64,out_size=8,kernel_size=3,t_shape=self.t_embedding_dim,attn=False),\n",
    "            F_x_t(in_channels=64,out_channels=32,out_size=16,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "            F_x_t(in_channels=32,out_channels=16,out_size=32,kernel_size=3,t_shape=self.t_embedding_dim),\n",
    "        ])\n",
    "        # self.end_mlp = nn.Conv2d(32,1,kernel_size=3,padding=1)\n",
    "        self.end_mlp = nn.Conv2d(16,1,kernel_size=1)\n",
    "        self.apply_init()\n",
    "    \n",
    "    def apply_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self,x,t):\n",
    "        x = x.reshape(-1,1,28,28)\n",
    "        x = F.pad(x,(2,2,2,2),mode='constant',value=0)\n",
    "        ttensor = self.t_embedding(t) # [batch, 256]\n",
    "        batch = x.shape[0]\n",
    "        # xc = x.clone()            print(attn_score.shape)\n",
    "\n",
    "        ups = []\n",
    "        for ly in self.up:\n",
    "            x = ly(x,ttensor)\n",
    "            ups.append(x.clone()) # append: 28x28, 14x14\n",
    "            x = nn.AvgPool2d(2)(x)\n",
    "        for ly in self.middle:\n",
    "            x = ly(x,ttensor)\n",
    "        for ly in self.down:\n",
    "            x = nn.Upsample(scale_factor=2)(x) + ups.pop() # 14x14, 28x28\n",
    "            x = ly(x,ttensor)\n",
    "            # x = nn.Upsample(scale_factor=2)(x) + ups.pop()\n",
    "        x = self.end_mlp(x)\n",
    "        x = x[:,:,2:30,2:30]\n",
    "        return x.reshape(batch,28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appended /home/zhh24/DeepLearning\n",
      "tensor([9.9970e-01, 9.9932e-01, 9.9886e-01, 9.9832e-01, 9.9771e-01, 9.9701e-01,\n",
      "        9.9624e-01, 9.9538e-01, 9.9445e-01, 9.9344e-01, 9.9235e-01, 9.9118e-01,\n",
      "        9.8994e-01, 9.8862e-01, 9.8722e-01, 9.8575e-01, 9.8420e-01, 9.8257e-01,\n",
      "        9.8087e-01, 9.7909e-01, 9.7724e-01, 9.7531e-01, 9.7331e-01, 9.7124e-01,\n",
      "        9.6910e-01, 9.6688e-01, 9.6459e-01, 9.6223e-01, 9.5979e-01, 9.5729e-01,\n",
      "        9.5472e-01, 9.5208e-01, 9.4937e-01, 9.4659e-01, 9.4375e-01, 9.4084e-01,\n",
      "        9.3786e-01, 9.3482e-01, 9.3171e-01, 9.2854e-01, 9.2531e-01, 9.2201e-01,\n",
      "        9.1865e-01, 9.1523e-01, 9.1176e-01, 9.0822e-01, 9.0462e-01, 9.0097e-01,\n",
      "        8.9726e-01, 8.9349e-01, 8.8967e-01, 8.8579e-01, 8.8186e-01, 8.7788e-01,\n",
      "        8.7384e-01, 8.6976e-01, 8.6562e-01, 8.6144e-01, 8.5720e-01, 8.5292e-01,\n",
      "        8.4859e-01, 8.4422e-01, 8.3980e-01, 8.3534e-01, 8.3084e-01, 8.2629e-01,\n",
      "        8.2171e-01, 8.1708e-01, 8.1241e-01, 8.0771e-01, 8.0297e-01, 7.9819e-01,\n",
      "        7.9338e-01, 7.8854e-01, 7.8366e-01, 7.7875e-01, 7.7380e-01, 7.6883e-01,\n",
      "        7.6383e-01, 7.5880e-01, 7.5374e-01, 7.4866e-01, 7.4355e-01, 7.3842e-01,\n",
      "        7.3326e-01, 7.2808e-01, 7.2288e-01, 7.1766e-01, 7.1242e-01, 7.0716e-01,\n",
      "        7.0189e-01, 6.9660e-01, 6.9129e-01, 6.8597e-01, 6.8063e-01, 6.7528e-01,\n",
      "        6.6992e-01, 6.6455e-01, 6.5917e-01, 6.5378e-01, 6.4838e-01, 6.4298e-01,\n",
      "        6.3757e-01, 6.3215e-01, 6.2673e-01, 6.2131e-01, 6.1588e-01, 6.1045e-01,\n",
      "        6.0503e-01, 5.9960e-01, 5.9417e-01, 5.8874e-01, 5.8332e-01, 5.7790e-01,\n",
      "        5.7249e-01, 5.6708e-01, 5.6167e-01, 5.5628e-01, 5.5089e-01, 5.4551e-01,\n",
      "        5.4014e-01, 5.3477e-01, 5.2942e-01, 5.2408e-01, 5.1876e-01, 5.1344e-01,\n",
      "        5.0814e-01, 5.0285e-01, 4.9758e-01, 4.9233e-01, 4.8709e-01, 4.8186e-01,\n",
      "        4.7666e-01, 4.7147e-01, 4.6630e-01, 4.6116e-01, 4.5603e-01, 4.5092e-01,\n",
      "        4.4583e-01, 4.4077e-01, 4.3573e-01, 4.3071e-01, 4.2572e-01, 4.2074e-01,\n",
      "        4.1580e-01, 4.1088e-01, 4.0598e-01, 4.0111e-01, 3.9627e-01, 3.9145e-01,\n",
      "        3.8666e-01, 3.8190e-01, 3.7717e-01, 3.7246e-01, 3.6779e-01, 3.6314e-01,\n",
      "        3.5853e-01, 3.5394e-01, 3.4939e-01, 3.4486e-01, 3.4037e-01, 3.3591e-01,\n",
      "        3.3148e-01, 3.2708e-01, 3.2271e-01, 3.1838e-01, 3.1408e-01, 3.0981e-01,\n",
      "        3.0558e-01, 3.0138e-01, 2.9721e-01, 2.9308e-01, 2.8898e-01, 2.8492e-01,\n",
      "        2.8089e-01, 2.7689e-01, 2.7293e-01, 2.6901e-01, 2.6512e-01, 2.6126e-01,\n",
      "        2.5744e-01, 2.5366e-01, 2.4991e-01, 2.4619e-01, 2.4252e-01, 2.3887e-01,\n",
      "        2.3527e-01, 2.3170e-01, 2.2816e-01, 2.2466e-01, 2.2120e-01, 2.1777e-01,\n",
      "        2.1438e-01, 2.1102e-01, 2.0770e-01, 2.0442e-01, 2.0117e-01, 1.9796e-01,\n",
      "        1.9478e-01, 1.9164e-01, 1.8853e-01, 1.8546e-01, 1.8242e-01, 1.7942e-01,\n",
      "        1.7645e-01, 1.7352e-01, 1.7063e-01, 1.6777e-01, 1.6494e-01, 1.6215e-01,\n",
      "        1.5939e-01, 1.5667e-01, 1.5398e-01, 1.5132e-01, 1.4870e-01, 1.4611e-01,\n",
      "        1.4356e-01, 1.4104e-01, 1.3855e-01, 1.3609e-01, 1.3367e-01, 1.3128e-01,\n",
      "        1.2892e-01, 1.2659e-01, 1.2430e-01, 1.2204e-01, 1.1981e-01, 1.1761e-01,\n",
      "        1.1544e-01, 1.1330e-01, 1.1119e-01, 1.0912e-01, 1.0707e-01, 1.0505e-01,\n",
      "        1.0307e-01, 1.0111e-01, 9.9179e-02, 9.7280e-02, 9.5408e-02, 9.3566e-02,\n",
      "        9.1751e-02, 8.9964e-02, 8.8205e-02, 8.6473e-02, 8.4769e-02, 8.3091e-02,\n",
      "        8.1440e-02, 7.9815e-02, 7.8216e-02, 7.6643e-02, 7.5096e-02, 7.3574e-02,\n",
      "        7.2077e-02, 7.0604e-02, 6.9156e-02, 6.7733e-02, 6.6333e-02, 6.4957e-02,\n",
      "        6.3604e-02, 6.2274e-02, 6.0967e-02, 5.9683e-02, 5.8421e-02, 5.7181e-02,\n",
      "        5.5963e-02, 5.4766e-02, 5.3591e-02, 5.2436e-02, 5.1303e-02, 5.0189e-02,\n",
      "        4.9096e-02, 4.8023e-02, 4.6969e-02, 4.5935e-02, 4.4920e-02, 4.3924e-02,\n",
      "        4.2946e-02, 4.1987e-02, 4.1045e-02, 4.0122e-02, 3.9216e-02, 3.8328e-02,\n",
      "        3.7456e-02, 3.6602e-02, 3.5764e-02, 3.4942e-02, 3.4136e-02, 3.3347e-02,\n",
      "        3.2573e-02, 3.1814e-02, 3.1070e-02, 3.0342e-02, 2.9628e-02, 2.8928e-02,\n",
      "        2.8243e-02, 2.7572e-02, 2.6914e-02, 2.6270e-02, 2.5639e-02, 2.5022e-02,\n",
      "        2.4417e-02, 2.3825e-02, 2.3245e-02, 2.2678e-02, 2.2123e-02, 2.1579e-02,\n",
      "        2.1047e-02, 2.0527e-02, 2.0018e-02, 1.9520e-02, 1.9033e-02, 1.8556e-02,\n",
      "        1.8090e-02, 1.7634e-02, 1.7188e-02, 1.6752e-02, 1.6326e-02, 1.5909e-02,\n",
      "        1.5502e-02, 1.5104e-02, 1.4715e-02, 1.4335e-02, 1.3963e-02, 1.3600e-02,\n",
      "        1.3245e-02, 1.2899e-02, 1.2561e-02, 1.2230e-02, 1.1907e-02, 1.1592e-02,\n",
      "        1.1284e-02, 1.0984e-02, 1.0690e-02, 1.0404e-02, 1.0124e-02, 9.8513e-03,\n",
      "        9.5850e-03, 9.3252e-03, 9.0716e-03, 8.8242e-03, 8.5829e-03, 8.3474e-03,\n",
      "        8.1178e-03, 7.8939e-03, 7.6754e-03, 7.4625e-03, 7.2548e-03, 7.0523e-03,\n",
      "        6.8550e-03, 6.6626e-03, 6.4751e-03, 6.2923e-03, 6.1142e-03, 5.9407e-03,\n",
      "        5.7716e-03, 5.6068e-03, 5.4463e-03, 5.2900e-03, 5.1377e-03, 4.9895e-03,\n",
      "        4.8451e-03, 4.7045e-03, 4.5676e-03, 4.4343e-03, 4.3045e-03, 4.1782e-03,\n",
      "        4.0553e-03, 3.9357e-03, 3.8193e-03, 3.7060e-03, 3.5958e-03, 3.4886e-03,\n",
      "        3.3843e-03, 3.2829e-03, 3.1842e-03, 3.0882e-03, 2.9949e-03, 2.9042e-03,\n",
      "        2.8160e-03, 2.7302e-03, 2.6469e-03, 2.5658e-03, 2.4871e-03, 2.4106e-03,\n",
      "        2.3362e-03, 2.2639e-03, 2.1937e-03, 2.1255e-03, 2.0593e-03, 1.9949e-03,\n",
      "        1.9324e-03, 1.8717e-03, 1.8128e-03, 1.7556e-03, 1.7000e-03, 1.6461e-03,\n",
      "        1.5937e-03, 1.5429e-03, 1.4936e-03, 1.4457e-03, 1.3993e-03, 1.3542e-03,\n",
      "        1.3105e-03, 1.2681e-03, 1.2270e-03, 1.1871e-03, 1.1484e-03, 1.1108e-03,\n",
      "        1.0744e-03, 1.0392e-03, 1.0049e-03, 9.7179e-04, 9.3964e-04, 9.0849e-04,\n",
      "        8.7829e-04, 8.4903e-04, 8.2067e-04, 7.9320e-04, 7.6658e-04, 7.4080e-04,\n",
      "        7.1582e-04, 6.9163e-04, 6.6820e-04, 6.4552e-04, 6.2355e-04, 6.0228e-04,\n",
      "        5.8168e-04, 5.6175e-04, 5.4245e-04, 5.2377e-04, 5.0570e-04, 4.8821e-04,\n",
      "        4.7128e-04, 4.5490e-04, 4.3906e-04, 4.2373e-04, 4.0891e-04, 3.9457e-04,\n",
      "        3.8070e-04, 3.6729e-04, 3.5432e-04, 3.4178e-04, 3.2966e-04, 3.1795e-04,\n",
      "        3.0662e-04, 2.9567e-04, 2.8509e-04, 2.7487e-04, 2.6499e-04, 2.5544e-04,\n",
      "        2.4622e-04, 2.3731e-04, 2.2871e-04, 2.2040e-04, 2.1237e-04, 2.0462e-04,\n",
      "        1.9713e-04, 1.8991e-04, 1.8293e-04, 1.7619e-04, 1.6969e-04, 1.6342e-04,\n",
      "        1.5736e-04, 1.5152e-04, 1.4588e-04, 1.4044e-04, 1.3519e-04, 1.3013e-04,\n",
      "        1.2524e-04, 1.2053e-04, 1.1599e-04, 1.1161e-04, 1.0738e-04, 1.0331e-04,\n",
      "        9.9383e-05, 9.5598e-05, 9.1949e-05, 8.8432e-05, 8.5042e-05, 8.1776e-05,\n",
      "        7.8628e-05, 7.5596e-05, 7.2674e-05, 6.9860e-05, 6.7149e-05, 6.4538e-05,\n",
      "        6.2023e-05, 5.9601e-05, 5.7269e-05, 5.5024e-05, 5.2863e-05, 5.0782e-05,\n",
      "        4.8779e-05, 4.6851e-05, 4.4995e-05, 4.3210e-05, 4.1492e-05, 3.9839e-05,\n",
      "        3.8248e-05, 3.6718e-05], device='cuda:0')\n",
      "Number parameters of the model: 221393\n",
      "Model strcuture: DDPM(\n",
      "  (t_embedding): SinousEmbedding()\n",
      "  (up): ModuleList(\n",
      "    (0): F_x_t(\n",
      "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (1): F_x_t(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=64, bias=True)\n",
      "    )\n",
      "    (2): F_x_t(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (middle): ModuleList(\n",
      "    (0): F_x_t(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (down): ModuleList(\n",
      "    (0): F_x_t(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=64, bias=True)\n",
      "    )\n",
      "    (1): F_x_t(\n",
      "      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (2): F_x_t(\n",
      "      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (fc): Linear(in_features=32, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (end_mlp): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 15.6916:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/init_visualize.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 1.3062: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.98it/s]\n",
      "epoch 0, MSE 0.2242, [Valid] 0.2242: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DDPM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SinousEmbedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/nobackup/users/zhh24/anaconda3/envs/DYY/lib/python3.7/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type F_x_t. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "epoch 1, loss 0.2487:   1%|█                                                                                                      | 1/94 [00:00<00:11,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[0.9956701993942261, 0.9959710240364075, 1.0530003309249878, 0.9213144779205322, 1.057141661643982, 0.9751720428466797, 0.9680765867233276, 1.0060406923294067, 0.9209141731262207, 1.0358518362045288, 0.9515738487243652, 0.9217539429664612, 0.9214352965354919, 0.895706832408905, 0.9493274092674255, 1.0191142559051514, 1.0628652572631836, 0.9125326871871948, 0.9925356507301331, 1.0155960321426392]\n",
      "[1.1694530248641968, 0.7616725564002991, 0.6008954048156738, 0.4027009904384613, 0.2939302921295166, 0.19253948330879211, 0.1724560707807541, 0.14846542477607727, 0.14206650853157043, 0.10852748155593872, 0.12213975191116333, 0.11564258486032486, 0.07759293913841248, 0.08571121096611023, 0.09568581730127335, 0.09735588729381561, 0.0881228893995285, 0.08260675519704819, 0.08216968923807144, 0.08646262437105179]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.2006: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.20it/s]\n",
      "epoch 1, MSE 0.1834, [Valid] 0.1834: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.62it/s]\n",
      "epoch 2, loss 0.1743: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.22it/s]\n",
      "epoch 2, MSE 0.1695, [Valid] 0.1695: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.57it/s]\n",
      "epoch 3, loss 0.1563: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 3, MSE 0.1491, [Valid] 0.1491: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n",
      "epoch 4, loss 0.1425: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.02it/s]\n",
      "epoch 4, MSE 0.1397, [Valid] 0.1397: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.56it/s]\n",
      "epoch 5, loss 0.1342: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 5, MSE 0.1303, [Valid] 0.1303: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6, loss 0.1371:   1%|█                                                                                                      | 1/94 [00:00<00:11,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[0.9825389385223389, 0.9264845252037048, 1.004364252090454, 1.0104691982269287, 1.0628550052642822, 1.0675299167633057, 0.9943296313285828, 1.1101744174957275, 1.0010329484939575, 0.988094687461853, 1.0674560070037842, 0.865959644317627, 0.9674904942512512, 0.9638899564743042, 0.9732338786125183, 1.0268019437789917, 0.9478619694709778, 1.0055363178253174, 1.0176571607589722, 0.9955370426177979]\n",
      "[1.0310436487197876, 0.6248946785926819, 0.38352417945861816, 0.25659647583961487, 0.1409003734588623, 0.11699353158473969, 0.07434860616922379, 0.10285764932632446, 0.08510708063840866, 0.05572989583015442, 0.05734134092926979, 0.036180052906274796, 0.030673854053020477, 0.03400362655520439, 0.02266652137041092, 0.028364546597003937, 0.026038408279418945, 0.023089777678251266, 0.027797138318419456, 0.025095488876104355]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6, loss 0.1265: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.07it/s]\n",
      "epoch 6, MSE 0.1231, [Valid] 0.1231: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n",
      "epoch 7, loss 0.1188: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.02it/s]\n",
      "epoch 7, MSE 0.1178, [Valid] 0.1178: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.51it/s]\n",
      "epoch 8, loss 0.1162: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.49it/s]\n",
      "epoch 8, MSE 0.1144, [Valid] 0.1144: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "epoch 9, loss 0.1114: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.05it/s]\n",
      "epoch 9, MSE 0.1137, [Valid] 0.1137: 100%|███████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.52it/s]\n",
      "epoch 10, loss 0.1091: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.05it/s]\n",
      "epoch 10, MSE 0.1044, [Valid] 0.1044: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11, loss 0.1144:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[0.9978609681129456, 1.026345133781433, 1.025437355041504, 0.9519157409667969, 1.0062947273254395, 0.9963005185127258, 0.9604605436325073, 1.0790499448776245, 0.9461386203765869, 0.9904152750968933, 0.9842007756233215, 0.9609602689743042, 0.9428297877311707, 1.0503206253051758, 1.006227731704712, 0.9509789347648621, 1.0208739042282104, 0.9768456816673279, 1.0350576639175415, 0.9944168329238892]\n",
      "[1.0131313800811768, 0.5742236971855164, 0.27272656559944153, 0.1465596854686737, 0.09657861292362213, 0.06521821022033691, 0.06345497071743011, 0.07035114616155624, 0.059618908911943436, 0.0492686964571476, 0.04206366837024689, 0.027325376868247986, 0.02067326009273529, 0.024280162528157234, 0.016474884003400803, 0.019069751724600792, 0.019910290837287903, 0.01644320972263813, 0.020050616934895515, 0.01681510917842388]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11, loss 0.1054: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.26it/s]\n",
      "epoch 11, MSE 0.1026, [Valid] 0.1026: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.56it/s]\n",
      "epoch 12, loss 0.1019: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 12, MSE 0.1004, [Valid] 0.1004: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n",
      "epoch 13, loss 0.1025: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.99it/s]\n",
      "epoch 13, MSE 0.0996, [Valid] 0.0996: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "epoch 14, loss 0.0999: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.98it/s]\n",
      "epoch 14, MSE 0.0995, [Valid] 0.0995: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.52it/s]\n",
      "epoch 15, loss 0.0969: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.99it/s]\n",
      "epoch 15, MSE 0.0947, [Valid] 0.0947: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16, loss 0.1100:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[0.9277873635292053, 0.9883667230606079, 1.0120646953582764, 1.0077815055847168, 1.0270980596542358, 1.0182219743728638, 1.0070602893829346, 1.0246878862380981, 0.9759447574615479, 1.031385898590088, 1.0254193544387817, 1.0323357582092285, 1.1017566919326782, 1.0779573917388916, 0.953021764755249, 1.0141795873641968, 0.9808624982833862, 1.0504343509674072, 0.9704107046127319, 0.9613288640975952]\n",
      "[1.00008225440979, 0.5223508477210999, 0.2271416336297989, 0.12941516935825348, 0.07243644446134567, 0.06238614767789841, 0.05434912070631981, 0.0736839696764946, 0.06080454960465431, 0.04770956188440323, 0.04445171356201172, 0.020623812451958656, 0.019194168969988823, 0.018933994695544243, 0.015203830786049366, 0.014893115498125553, 0.01425221934914589, 0.013959670439362526, 0.016554253175854683, 0.013789115473628044]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_15.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16, loss 0.0948: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.71it/s]\n",
      "epoch 16, MSE 0.0966, [Valid] 0.0966: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.61it/s]\n",
      "epoch 17, loss 0.0924: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.98it/s]\n",
      "epoch 17, MSE 0.0948, [Valid] 0.0948: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.58it/s]\n",
      "epoch 18, loss 0.0934: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.98it/s]\n",
      "epoch 18, MSE 0.0928, [Valid] 0.0928: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.54it/s]\n",
      "epoch 19, loss 0.0921: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.60it/s]\n",
      "epoch 19, MSE 0.0913, [Valid] 0.0913: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "epoch 20, loss 0.0900: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.96it/s]\n",
      "epoch 20, MSE 0.0892, [Valid] 0.0892: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21, loss 0.0883:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[1.0054829120635986, 0.9600141644477844, 0.9670820832252502, 0.9969930648803711, 1.105242133140564, 0.9098739624023438, 1.0457936525344849, 0.9826421141624451, 1.1149725914001465, 1.007585883140564, 1.0218641757965088, 1.0435781478881836, 1.0076148509979248, 0.9794421792030334, 0.9783692955970764, 0.9049535989761353, 0.9323753714561462, 0.9648674130439758, 1.0208112001419067, 1.0206615924835205]\n",
      "[1.0215849876403809, 0.4916878342628479, 0.19255805015563965, 0.12136484682559967, 0.06572921574115753, 0.050229642540216446, 0.052371297031641006, 0.06919031590223312, 0.07220511883497238, 0.044570907950401306, 0.03776051104068756, 0.020022330805659294, 0.01681990548968315, 0.016037724912166595, 0.013075018301606178, 0.012123528867959976, 0.01115206815302372, 0.010894419625401497, 0.013428990729153156, 0.011934328824281693]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_20.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21, loss 0.0899: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.18it/s]\n",
      "epoch 21, MSE 0.0888, [Valid] 0.0888: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.59it/s]\n",
      "epoch 22, loss 0.0886: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.99it/s]\n",
      "epoch 22, MSE 0.0833, [Valid] 0.0833: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.51it/s]\n",
      "epoch 23, loss 0.0874: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.00it/s]\n",
      "epoch 23, MSE 0.0868, [Valid] 0.0868: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "epoch 24, loss 0.0861: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.03it/s]\n",
      "epoch 24, MSE 0.0852, [Valid] 0.0852: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.58it/s]\n",
      "epoch 25, loss 0.0862: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.98it/s]\n",
      "epoch 25, MSE 0.0854, [Valid] 0.0854: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 26, loss 0.0822:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[0.9959306120872498, 0.9339210987091064, 0.9340528845787048, 0.9093735218048096, 0.977450966835022, 0.9783138036727905, 0.9290589094161987, 1.0871658325195312, 0.9871878623962402, 0.9656217694282532, 1.004308819770813, 1.0306081771850586, 1.0518910884857178, 0.9508032202720642, 0.9677475690841675, 0.9302875399589539, 0.877405047416687, 0.9941999316215515, 0.9616425037384033, 1.0169779062271118]\n",
      "[0.995722234249115, 0.40486934781074524, 0.15271854400634766, 0.10176672041416168, 0.07851235568523407, 0.04892120137810707, 0.04458837956190109, 0.05189305171370506, 0.07471700012683868, 0.04285229742527008, 0.03282461687922478, 0.018853040412068367, 0.016596559435129166, 0.013149762526154518, 0.01288331113755703, 0.012183967977762222, 0.009463801048696041, 0.011080751195549965, 0.010864030569791794, 0.009837769903242588]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 26, loss 0.0844: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.23it/s]\n",
      "epoch 26, MSE 0.0844, [Valid] 0.0844: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.58it/s]\n",
      "epoch 27, loss 0.0835: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.00it/s]\n",
      "epoch 27, MSE 0.0852, [Valid] 0.0852: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.56it/s]\n",
      "epoch 28, loss 0.0821: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.99it/s]\n",
      "epoch 28, MSE 0.0814, [Valid] 0.0814: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n",
      "epoch 29, loss 0.0815: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.00it/s]\n",
      "epoch 29, MSE 0.0791, [Valid] 0.0791: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.55it/s]\n",
      "epoch 30, loss 0.0791: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 30, MSE 0.0777, [Valid] 0.0777: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualize to /home/zhh24/samples/diffuse_epoch_30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 31, loss 0.0934:   1%|█                                                                                                     | 1/94 [00:00<00:11,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000299990177154541, 0.033122241497039795, 0.11033189296722412, 0.22125422954559326, 0.35161757469177246, 0.4865582585334778, 0.6133379936218262, 0.7231091856956482, 0.8114710450172424, 0.8779618144035339, 0.924903929233551, 0.956076443195343, 0.975583016872406, 0.9871010184288025, 0.993524968624115, 0.9969117641448975, 0.9986007213592529, 0.9993976950645447, 0.9997537732124329, 0.9999043941497803]\n",
      "[1.0340079069137573, 0.953088641166687, 0.9939531683921814, 0.992101788520813, 0.9892802238464355, 1.0356539487838745, 1.0303881168365479, 0.9871862530708313, 0.9763270020484924, 1.0519763231277466, 1.053636908531189, 0.9414492249488831, 1.0695143938064575, 0.9721750617027283, 1.030295729637146, 0.9317366480827332, 1.0036790370941162, 1.0327701568603516, 0.9880707263946533, 0.9726787805557251]\n",
      "[1.0466264486312866, 0.3561263084411621, 0.13949432969093323, 0.11477505415678024, 0.06897366791963577, 0.08928248286247253, 0.03117264434695244, 0.06624994426965714, 0.06319433450698853, 0.04168056696653366, 0.03875814005732536, 0.017996560782194138, 0.015155571512877941, 0.013255284167826176, 0.011862004175782204, 0.011135091073811054, 0.010221758857369423, 0.011551248840987682, 0.010733569040894508, 0.009983926080167294]\n",
      "Saved denoise to /home/zhh24/samples/denoise_epoch_30.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 31, loss 0.0785: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 31, MSE 0.0791, [Valid] 0.0791: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.52it/s]\n",
      "epoch 32, loss 0.0785: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  8.01it/s]\n",
      "epoch 32, MSE 0.0783, [Valid] 0.0783: 100%|██████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.53it/s]\n",
      "epoch 33, loss 0.0766: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:12<00:00,  7.97it/s]\n",
      "epoch 33, MSE 0.0758, [Valid] 0.0758:  54%|██████████████████████████████████████████████▌                                       | 13/24 [00:01<00:01,  8.33it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8080/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath('/home/zhh24/DeepLearning')\n",
    "\n",
    "sys.path.append(parent_dir)\n",
    "print('appended',parent_dir)\n",
    "\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "mnist = utils.MNIST(batch_size=512)\n",
    "train_loader = mnist.train_dataloader\n",
    "valid_loader = mnist.valid_dataloader\n",
    "T=500\n",
    "beta1=3e-4 # variance of lowest temperature\n",
    "betaT=4e-2 # variance of highest temperature\n",
    "# MODIFIED\n",
    "\n",
    "# step = torch.log(torch.tensor(betaT/beta1))/(T-1)\n",
    "# betas = beta1 * torch.exp(step*torch.arange(T,dtype=torch.float).to(device))\n",
    "step = (betaT-beta1)/(T-1)\n",
    "betas = torch.arange(T,dtype=torch.float,device=device) * step + beta1\n",
    "\n",
    "\n",
    "alphas = 1-betas\n",
    "alpha_bars = alphas.clone()\n",
    "for i in range(1,T):\n",
    "    alpha_bars[i] *= alpha_bars[i-1]\n",
    "print(alpha_bars)\n",
    "# print(alphas)\n",
    "\n",
    "sqrt = torch.sqrt\n",
    "sigmas = sqrt(betas * (1-alpha_bars / alphas)/(1-alpha_bars))\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model:DDPM,save_dir):\n",
    "    x = torch.randn([100,784]).to(device)\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*sigmas[t]\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "    grid = torchvision.utils.make_grid(post_process(x).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize(model,save_dir):\n",
    "    x = torch.randn([10,784]).to(device)\n",
    "    x_history = []\n",
    "    for t in range(T-1,-1,-1):\n",
    "        sigmaz = torch.randn_like(x)*((betas[t])**0.5).to(device)\n",
    "        if t==0:\n",
    "            sigmaz = 0\n",
    "        x = (x-(1-alphas[t])/(sqrt(1-alpha_bars[t]))*model(x,t*torch.ones(x.shape[0],dtype=torch.long,device=device)))/(sqrt(alphas[t]))+sigmaz\n",
    "        # x = torch.clamp(x,0,1)\n",
    "        x_history.append(x)\n",
    "    # print('cat.shape',torch.cat(x_history,dim=0).shape)\n",
    "    grid = torchvision.utils.make_grid(post_process(torch.cat(x_history,dim=0)[3::4,...]).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "    print('Saved visualize to',os.path.abspath(save_dir))\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_denoise(model,save_dir):\n",
    "    # get 10 images from the dataset\n",
    "    x,_ = next(iter(valid_loader))\n",
    "    x = x[:20,...].reshape(20,784).to(device)\n",
    "    x = pre_process(x)\n",
    "    t = torch.tensor([i * T // 20 for i in range(20)],dtype=torch.long,device=device)\n",
    "    noise = torch.randn_like(x).reshape(-1,784)\n",
    "    v1 = (sqrt(alpha_bars[t]).reshape(-1,1)*x).reshape(-1,784)\n",
    "    v2 = sqrt(1-alpha_bars[t]).reshape(-1,1)*noise\n",
    "    x_corr = v1+v2\n",
    "    est = model(x_corr,t)\n",
    "    x_rec = (x_corr - sqrt(1-alpha_bars[t]).reshape(-1,1)*est)/(sqrt(alpha_bars[t])).reshape(-1,1)\n",
    "    grid_orig = torchvision.utils.make_grid(post_process(x).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    grid_corr = torchvision.utils.make_grid(post_process(x_corr).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    grid_rec = torchvision.utils.make_grid(post_process(x_rec).reshape(-1,1,28,28).cpu(), nrow=10)\n",
    "    # add noise level infomation to the image\n",
    "    noise_level = (1-alpha_bars[t]).reshape(-1).tolist()\n",
    "    ori_mse = noise.pow(2).mean(dim=1).reshape(-1).tolist()\n",
    "    mse = ((est-noise)**2).mean(dim=1).reshape(-1).tolist()\n",
    "    print(noise_level)\n",
    "    print(ori_mse)\n",
    "    print(mse)\n",
    "    grid = torch.cat([grid_orig,grid_corr,grid_rec],dim=1)\n",
    "    torchvision.utils.save_image(grid, save_dir)\n",
    "    print('Saved denoise to',os.path.abspath(save_dir))\n",
    "\n",
    "def pre_process(x):\n",
    "    # do the logit transform\n",
    "    # return (torch.log(x+1e-3)-torch.log(1-x+1e-3))\n",
    "    return x*2-1 #MODIFIED\n",
    "    return (x+1)/2\n",
    "\n",
    "def post_process(x):\n",
    "    # return torch.sigmoid(x)\n",
    "    return (x+1)/2 #MODIFIED\n",
    "    return x*2-1\n",
    "\n",
    "def train(epochs,model:DDPM,optimizer,eval_interval=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        with tqdm(train_loader) as bar:\n",
    "            losses = []\n",
    "            for x,_ in bar:\n",
    "                x = pre_process(x.to(device))\n",
    "                epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                alpha_tbars = alpha_bars[ts]\n",
    "                value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                out = model(value,ts) # [batch,784]\n",
    "                # loss = ((epss-out).pow(2).mean(dim=-1) * (betas[ts])/(2*alphas[ts]*(1-alpha_tbars))).sum(dim=0)\n",
    "                loss = (epss-out).pow(2).mean(dim=-1).mean(dim=0)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "                bar.set_description('epoch {}, loss {:.4f}'.format(epoch,sum(losses)/len(losses)))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(valid_loader) as bar:\n",
    "                mses = []\n",
    "                losses = []\n",
    "                for x,_ in bar:\n",
    "                    x = pre_process(x.to(device))\n",
    "                    epss = torch.randn_like(x).reshape(-1,784).to(device)\n",
    "                    ts = torch.randint(0,T,(x.shape[0],),device=device,dtype=torch.long)\n",
    "                    # print(ts)\n",
    "                    alpha_tbars = alpha_bars[ts]\n",
    "                    value = (sqrt(alpha_tbars).reshape(-1,1,1,1)*x).reshape(-1,784)+sqrt(1-alpha_tbars).reshape(-1,1)*epss\n",
    "                    out = model(value,ts)\n",
    "                    mse = F.mse_loss(epss,out)\n",
    "                    mses.append(mse.item())\n",
    "                    # loss = ((epss-out).pow(2).mean(dim=-1) * (betas[ts])/(2*alphas[ts]*(1-alpha_tbars))).sum(dim=0)\n",
    "                    loss = (epss-out).pow(2).mean(dim=-1).mean(dim=0)\n",
    "                    losses.append(loss.item())\n",
    "                    bar.set_description('epoch {}, MSE {:.4f}, [Valid] {:.4f}'.format(epoch,sum(mses)/len(mses),sum(losses)/len(losses)))\n",
    "                    \n",
    "        if epoch % eval_interval == 0:\n",
    "            visualize(model,save_dir=os.path.join('./samples',f'diffuse_epoch_{epoch}.png'))\n",
    "            sample(model,save_dir=os.path.join('./samples',f'sample_epoch_{epoch}.png'))\n",
    "            visualize_denoise(model,save_dir=os.path.join('./samples',f'denoise_epoch_{epoch}.png'))\n",
    "            torch.save(model,os.path.join('./samples',f'epoch_{epoch}.pt'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = DDPM().to(device)\n",
    "    print('Number parameters of the model:', sum(p.numel() for p in model.parameters()))\n",
    "    print('Model strcuture:',model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    os.makedirs('./samples',exist_ok=True)\n",
    "    sample(model,save_dir=os.path.join('./samples',f'init.png'))\n",
    "    visualize(model,save_dir=os.path.join('./samples',f'init_visualize.png'))\n",
    "    train(200,model,optimizer,eval_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
